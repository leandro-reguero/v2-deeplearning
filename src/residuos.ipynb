{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import os\n",
    "# import zipfile\n",
    "# import pathlib\n",
    "\n",
    "# # Descargar el archivo ZIP manualmente\n",
    "# url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
    "# zip_path = tf.keras.utils.get_file('kagglecatsanddogs_5340.zip', origin=url, extract=False)\n",
    "\n",
    "# # Descomprimir el archivo ZIP\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(os.path.dirname(zip_path))\n",
    "\n",
    "# # Definir la ruta al directorio descomprimido\n",
    "# extracted_path = os.path.join(os.path.dirname(zip_path), 'PetImages')\n",
    "\n",
    "# # Crear un dataset de TensorFlow a partir del directorio descomprimido\n",
    "# data_dir = pathlib.Path(extracted_path)\n",
    "\n",
    "# # Parámetros del dataset\n",
    "# batch_size = 32\n",
    "# img_height = 128\n",
    "# img_width = 128\n",
    "\n",
    "# # Crear el dataset de entrenamiento y validación\n",
    "# train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#   data_dir,\n",
    "#   validation_split=0.2,\n",
    "#   subset=\"training\",\n",
    "#   seed=123,\n",
    "#   image_size=(img_height, img_width),\n",
    "#   batch_size=batch_size)\n",
    "# val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#   data_dir,\n",
    "#   validation_split=0.2,\n",
    "#   subset=\"validation\",\n",
    "#   seed=123,\n",
    "#   image_size=(img_height, img_width),\n",
    "#   batch_size=batch_size)\n",
    "\n",
    "# # Normalizar los valores de los píxeles de 0-255 a 0-1\n",
    "# normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "# normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "# normalized_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# # Imprimir la estructura del dataset\n",
    "# for image_batch, labels_batch in normalized_train_ds:\n",
    "#     print(image_batch.shape)\n",
    "#     print(labels_batch.shape)\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
